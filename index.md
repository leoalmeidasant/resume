# Leonardo de Almeida Santos
**Data Engineer | DataOps | Software Engineer**  
Itaquaquecetuba, SÃ£o Paulo, Brazil  

---

## ğŸ“« Contact  
- **Email:** 3fsleo@gmail.com  
- **LinkedIn:** [linkedin.com/in/leonrdalmeidasan](https://www.linkedin.com/in/leonrdalmeidasan)  

---

## ğŸ† Professional Summary  
Experienced **Data Engineer** with nearly a decade of expertise in **AWS, Software Engineering, scalable platform design, and infrastructure**. Over the past four years, I have been working extensively with **Databricks**, building **efficient and resilient data processing solutions**. Passionate about designing **robust and secure architectures** to ensure **scalability and performance** for large-scale data workloads. My focus is on **end-to-end data pipeline development**, emphasizing **best practices, automation, and technological innovation**.

---

## ğŸ”§ Core Skills  
- **Cloud & Infrastructure:** AWS (S3, EC2, EKS, Lambda), Kubernetes, Terraform, Docker  
- **Data Engineering:** Databricks, PySpark, Apache Airflow, Apache Kafka, Apache NiFi  
- **Programming & DevOps:** Python, GitLab CI/CD, YAML, DataOps  
- **Data Governance & Observability:** Data lineage, metric tracking, dataset monitoring  

---

## ğŸ’¼ Professional Experience  

### **iFood | Data Engineer**  
ğŸ“… *Feb 2022 - Present | SÃ£o Paulo, Brazil*  
- Maintain and enhance a **data ingestion, governance, and transformation platform** serving over **3,000 daily users**.
- Develop **microservices and libraries** to support the platform, leveraging **Kubernetes, Databricks, and AWS**.
- Build **data observability components** for monitoring datasets and tracking business metrics.
- Led a project implementing **Unity Catalog**, contributing to the creation of an **internal authentication service** managing access to multiple platforms, including Unity Catalog. This solution was fully **self-service and YAML-based**.
- In the second phase of this project, implemented **multi-catalog support** using **Databricks Unity Catalog**, enhancing the platform to manage access based on catalogs and **Service Principals**.
- Designed a **multi-catalog blueprint using Terraform**, automating the creation of catalogs and all necessary components across **Databricks and AWS**.
- Mentor engineers outside the team, sharing **DataOps** best practices across departments.

### **ESCALE | Data Solutions Architect**  
ğŸ“… *May 2021 - Feb 2022 (10 months)*  
- Led **technical evolution** of the data platform, designing a **streaming architecture** for large-scale ad data ingestion.
- Integrated **Google Ads, AWS, and Airflow** for data processing and analytics.
- Developed a **self-service DAG builder on Airflow**, enabling teams to create workflows without engineering support.

### **PicPay | Data Engineer**  
ğŸ“… *Apr 2020 - May 2021 (1 year 2 months)*  
- Built **data pipelines** using **Databricks and Airflow** to support business areas.
- Developed a **YAML-based pipeline automation tool** to streamline workflow management.
- Designed a **Change Data Capture (CDC) architecture** using **Debezium and Kafka**.

### **C6 Bank | Data Engineer**  
ğŸ“… *Jun 2019 - Mar 2020 (10 months)*  
- Designed and implemented a **multi-cloud data architecture** (AWS & GCP) with **end-to-end encryption**.
- Developed **data pipelines** using **Apache NiFi, Cloud Dataflow, and BigQuery**.
- Worked with **AWS Kinesis** for real-time data processing.

### **Datenworks | Data Engineer**  
ğŸ“… *Apr 2019 - Jun 2019 (3 months)*  
- Developed **data ingestion components** for a **GCP-based Data Lake**.
- Built pipelines using **Apache NiFi and Google Cloud Storage**.

### **QuintoAndar | Data Engineer**  
ğŸ“… *Sep 2018 - Apr 2019 (8 months)*  
- Modeled **Data Warehouse (Redshift)** using a **Star Schema** approach.
- Developed **Apache Airflow DAGs** for **data ingestion and orchestration**.

### **Rivendel Tecnologia | Data Engineer & DevOps Intern**  
ğŸ“… *Jan 2018 - Sep 2018 (9 months) | Data Engineer*  
ğŸ“… *Dec 2016 - Dec 2017 (1 year 1 month) | DevOps Intern*  
- Developed **big data processing** solutions using **Spark and Apache Beam**.
- Contributed to **Data Lake** projects for large enterprises in Brazil.

### **Itautec | IT Support Technician**  
ğŸ“… *Jul 2013 - Jan 2014 (7 months)*  
- Provided **Level 2 technical support** for **ItaÃº Bank's Administrative Center**.
- Performed **installations, updates, backups, and general IT support**.

---

## ğŸ“ Education  
- **Fatec Mogi das Cruzes** - BSc in **Systems Analysis and Development** *(2014 - 2018)*  
- **ETEC Itaquaquecetuba** - **Technical Degree in IT** *(2011 - 2012)*  
- **Udacity** - **Nanodegree in Data Streaming** *(Nov 2020 - Jan 2021)*  

---

## ğŸ“œ Certifications  
- **Data Streaming Nanodegree (Udacity)**  
- **Lean Startup: First Steps in Building a Lean Startup**  

---

## ğŸŒ Languages  
- **Portuguese** (Native)  
- **English** (Professional Proficiency)
